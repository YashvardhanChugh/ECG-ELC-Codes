{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1905968,"sourceType":"datasetVersion","datasetId":1136210}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:10:27.674938Z","iopub.execute_input":"2025-07-07T19:10:27.675460Z","iopub.status.idle":"2025-07-07T19:13:23.219882Z","shell.execute_reply.started":"2025-07-07T19:10:27.675441Z","shell.execute_reply":"2025-07-07T19:13:23.219071Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install numpy pandas scipy scikit-learn torch torchaudio matplotlib torch_geometric wfdb tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:20:26.166079Z","iopub.execute_input":"2025-07-07T19:20:26.166353Z","iopub.status.idle":"2025-07-07T19:21:58.351821Z","shell.execute_reply.started":"2025-07-07T19:20:26.166334Z","shell.execute_reply":"2025-07-07T19:21:58.351126Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport ast\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport wfdb\nfrom scipy.signal import butter, lfilter, resample\n\nfrom torch_geometric.nn import GCNConv, global_mean_pool\nfrom torch_geometric.data import Data as GraphData\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:22:10.159650Z","iopub.execute_input":"2025-07-07T19:22:10.160471Z","iopub.status.idle":"2025-07-07T19:22:22.968906Z","shell.execute_reply.started":"2025-07-07T19:22:10.160437Z","shell.execute_reply":"2025-07-07T19:22:22.968112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load metadata\ndf = pd.read_csv('/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/ptbxl_database.csv')\nscp_statements = pd.read_csv('/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/scp_statements.csv', index_col=0)\n\n# Use only diagnostic SCP codes\ndef extract_dominant_superclass(scp_dict):\n    filtered = {k: v for k, v in scp_dict.items() if k in scp_statements.index and scp_statements.loc[k, 'diagnostic'] == 1}\n    if not filtered:\n        return 'NORM'\n    dominant_code = max(filtered, key=filtered.get)\n    superclass = scp_statements.loc[dominant_code, 'diagnostic_class']\n    return superclass if pd.notna(superclass) else 'NORM'\n\ndf['scp_codes'] = df['scp_codes'].apply(ast.literal_eval)\ndf['diagnostic_superclass'] = df['scp_codes'].apply(extract_dominant_superclass)\n\n# Keep only the desired 5 superclasses\nvalid_superclasses = ['NORM', 'MI', 'STTC', 'CD', 'HYP']\ndf = df[df['diagnostic_superclass'].isin(valid_superclasses)]\n\n# Encode labels\nle = LabelEncoder()\ndf['class_id'] = le.fit_transform(df['diagnostic_superclass'])\n\nprint(\"\\nClass mapping:\")\nfor cls, idx in zip(le.classes_, range(len(le.classes_))):\n    print(f\"{idx}: {cls}\")\n\nprint(\"\\nDistribution:\")\nprint(df['diagnostic_superclass'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:22:30.126547Z","iopub.execute_input":"2025-07-07T19:22:30.126853Z","iopub.status.idle":"2025-07-07T19:22:31.182802Z","shell.execute_reply.started":"2025-07-07T19:22:30.126832Z","shell.execute_reply":"2025-07-07T19:22:31.182174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, test_df = train_test_split(\n    df,\n    test_size=0.2,\n    stratify=df['class_id'],\n    random_state=42\n)\n\ntrain_df, val_df = train_test_split(\n    train_df,\n    test_size=0.1,\n    stratify=train_df['class_id'],\n    random_state=42\n)\n\nprint(\"\\nTrain distribution:\\n\", train_df['diagnostic_superclass'].value_counts())\nprint(\"\\nValidation distribution:\\n\", val_df['diagnostic_superclass'].value_counts())\nprint(\"\\nTest distribution:\\n\", test_df['diagnostic_superclass'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:22:35.132926Z","iopub.execute_input":"2025-07-07T19:22:35.133529Z","iopub.status.idle":"2025-07-07T19:22:35.173003Z","shell.execute_reply.started":"2025-07-07T19:22:35.133507Z","shell.execute_reply":"2025-07-07T19:22:35.172269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def butter_bandpass(lowcut, highcut, fs, order=1):\n    b, a = butter(order, [lowcut/(0.5*fs), highcut/(0.5*fs)], btype='band')\n    return b, a\n\ndef bandpass_filter(data, lowcut=0.5, highcut=45.0, fs=500.0, order=1):\n    b, a = butter_bandpass(lowcut, highcut, fs, order)\n    return lfilter(b, a, data)\n\ndef preprocess_signal(signal, target_fs=100):\n    fs = 500\n    filtered = np.array([bandpass_filter(lead, fs=fs) for lead in signal])\n    if fs != target_fs:\n        filtered = resample(filtered, int(filtered.shape[1]*target_fs/fs), axis=1)\n    filtered = (filtered - filtered.mean(axis=1, keepdims=True)) / (filtered.std(axis=1, keepdims=True) + 1e-6)\n    return filtered.astype(np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:22:44.561140Z","iopub.execute_input":"2025-07-07T19:22:44.561672Z","iopub.status.idle":"2025-07-07T19:22:44.567088Z","shell.execute_reply.started":"2025-07-07T19:22:44.561651Z","shell.execute_reply":"2025-07-07T19:22:44.566523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PTBXLDataset(Dataset):\n    def __init__(self, df, data_dir):\n        self.df = df.reset_index(drop=True)\n        self.data_dir = data_dir\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        record = wfdb.rdrecord(os.path.join(self.data_dir, row['filename_hr']))\n        signal = record.p_signal.T\n        signal = preprocess_signal(signal)\n        label = row['class_id']\n        return torch.tensor(signal), torch.tensor(label)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:22:48.459144Z","iopub.execute_input":"2025-07-07T19:22:48.459668Z","iopub.status.idle":"2025-07-07T19:22:48.464536Z","shell.execute_reply.started":"2025-07-07T19:22:48.459643Z","shell.execute_reply":"2025-07-07T19:22:48.463837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HybridModel(nn.Module):\n    def __init__(self, n_classes):\n        super().__init__()\n        self.cnn = nn.Sequential(\n            nn.Conv1d(12, 32, kernel_size=7, padding=3), nn.ReLU(),\n            nn.Conv1d(32, 64, kernel_size=5, padding=2), nn.ReLU(),\n            nn.AdaptiveAvgPool1d(128)  # [B, 64, 128]\n        )\n        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=4)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n\n        self.fc = nn.Sequential(\n            nn.Linear(64, 32), nn.ReLU(),\n            nn.Linear(32, n_classes)\n        )\n\n    def forward(self, x):\n        x = self.cnn(x)                # [B, 64, 128]\n        x = x.permute(2, 0, 1)        # [128, B, 64] â†’ sequence_len, batch, features\n        x = self.transformer(x)      # [128, B, 64]\n        x = x.permute(1, 0, 2).mean(1)  # [B, 64] (mean over sequence_len)\n        out = self.fc(x)             # [B, n_classes]\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-05T19:59:33.597324Z","iopub.execute_input":"2025-07-05T19:59:33.598137Z","iopub.status.idle":"2025-07-05T19:59:33.607934Z","shell.execute_reply.started":"2025-07-05T19:59:33.598100Z","shell.execute_reply":"2025-07-05T19:59:33.607080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import torch\n# import torch.nn as nn\n\n# class HybridModel(nn.Module):\n#     def __init__(self, n_classes):\n#         super(HybridModel, self).__init__()\n        \n#         # CNN Feature Extractor\n#         self.cnn = nn.Sequential(\n#             nn.Conv1d(12, 32, kernel_size=7, padding=3), \n#             nn.BatchNorm1d(32), \n#             nn.ReLU(),\n#             nn.Conv1d(32, 64, kernel_size=5, padding=2), \n#             nn.BatchNorm1d(64),\n#             nn.ReLU(),\n#             nn.AdaptiveAvgPool1d(128)  # [B, 64, 128]\n#         )\n\n#         # Positional Encoding (optional but recommended for Transformers)\n#         self.pos_embedding = nn.Parameter(torch.randn(128, 1, 64))  # [Seq_len, 1, d_model]\n\n#         # Transformer Encoder\n#         encoder_layer = nn.TransformerEncoderLayer(\n#             d_model=64, nhead=4, dim_feedforward=256, dropout=0.1, batch_first=False\n#         )\n#         self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n\n#         # Final classification head\n#         self.fc = nn.Sequential(\n#             nn.Linear(64, 32),\n#             nn.ReLU(),\n#             nn.Dropout(0.3),\n#             nn.Linear(32, n_classes)\n#         )\n\n#     def forward(self, x):\n#         x = self.cnn(x)                  # [B, 64, 128]\n#         x = x.permute(2, 0, 1)           # [128, B, 64]\n\n#         # Add positional encoding\n#         x = x + self.pos_embedding       # [128, B, 64]\n\n#         x = self.transformer(x)          # [128, B, 64]\n#         x = x.permute(1, 0, 2).mean(dim=1)  # Global average pooling [B, 64]\n#         out = self.fc(x)                 # [B, n_classes]\n#         return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:23:01.229272Z","iopub.execute_input":"2025-07-07T19:23:01.229542Z","iopub.status.idle":"2025-07-07T19:23:01.237027Z","shell.execute_reply.started":"2025-07-07T19:23:01.229524Z","shell.execute_reply":"2025-07-07T19:23:01.236302Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_epoch(model, loader, optimizer, criterion, device, train=True):\n    model.train() if train else model.eval()\n    total_loss, correct, total = 0, 0, 0\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        if train:\n            optimizer.zero_grad()\n        logits = model(x)\n        loss = criterion(logits, y)\n        if train:\n            loss.backward()\n            optimizer.step()\n        total_loss += loss.item() * y.size(0)\n        preds = logits.argmax(1)\n        correct += (preds == y).sum().item()\n        total += y.size(0)\n    return total_loss/total, correct/total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:23:01.250966Z","iopub.execute_input":"2025-07-07T19:23:01.251710Z","iopub.status.idle":"2025-07-07T19:23:01.267808Z","shell.execute_reply.started":"2025-07-07T19:23:01.251686Z","shell.execute_reply":"2025-07-07T19:23:01.267050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = PTBXLDataset(train_df, '/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1')\nval_ds = PTBXLDataset(val_df, '/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1')\ntest_ds = PTBXLDataset(test_df, '/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1')\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=16)\ntest_loader = DataLoader(test_ds, batch_size=16)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"\\nUsing device: {device}\")\n\nmodel = HybridModel(len(le.classes_)).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:23:01.269178Z","iopub.execute_input":"2025-07-07T19:23:01.269473Z","iopub.status.idle":"2025-07-07T19:23:01.523926Z","shell.execute_reply.started":"2025-07-07T19:23:01.269452Z","shell.execute_reply":"2025-07-07T19:23:01.522954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_val_loss = float('inf')\nhistory = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n\nfor epoch in range(60):\n    print(f\"\\nEpoch {epoch+1}\")\n    train_loss, train_acc = run_epoch(model, train_loader, optimizer, criterion, device, train=True)\n    val_loss, val_acc = run_epoch(model, val_loader, optimizer, criterion, device, train=False)\n\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n\n    scheduler.step(val_loss)\n\n    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n    print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        torch.save(model.state_dict(), 'best_model.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:23:01.524727Z","iopub.execute_input":"2025-07-07T19:23:01.525010Z","iopub.status.idle":"2025-07-07T19:30:38.706096Z","shell.execute_reply.started":"2025-07-07T19:23:01.524985Z","shell.execute_reply":"2025-07-07T19:30:38.704977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12,5))\nplt.subplot(1,2,1)\nplt.plot(history['train_loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Val Loss')\nplt.title(\"Loss\"); plt.xlabel(\"Epoch\"); plt.legend()\nplt.subplot(1,2,2)\nplt.plot(history['train_acc'], label='Train Acc')\nplt.plot(history['val_acc'], label='Val Acc')\nplt.title(\"Accuracy\"); plt.xlabel(\"Epoch\"); plt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:30:38.706595Z","iopub.status.idle":"2025-07-07T19:30:38.706876Z","shell.execute_reply.started":"2025-07-07T19:30:38.706733Z","shell.execute_reply":"2025-07-07T19:30:38.706744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_model.pt'))\nmodel.eval()\n\ny_true, y_pred = [], []\nwith torch.no_grad():\n    for x, y in tqdm(test_loader, desc=\"Testing\"):\n        x = x.to(device)\n        logits = model(x)\n        preds = logits.argmax(1).cpu()\n        y_true.extend(y.tolist())\n        y_pred.extend(preds.tolist())\n\ntest_acc = np.mean(np.array(y_true) == np.array(y_pred))\nprint(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=le.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T19:30:38.707674Z","iopub.status.idle":"2025-07-07T19:30:38.708095Z","shell.execute_reply.started":"2025-07-07T19:30:38.707985Z","shell.execute_reply":"2025-07-07T19:30:38.707996Z"}},"outputs":[],"execution_count":null}]}